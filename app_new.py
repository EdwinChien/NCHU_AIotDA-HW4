import streamlit as st
import os
import tempfile
import warnings

# 1. å°å…¥æ ¸å¿ƒåŸºç¤å¥—ä»¶ (é¿é–‹å®¹æ˜“æ¶ˆå¤±çš„ .chains)
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.llms import HuggingFaceHub
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# å¿½ç•¥ç„¡é—œè­¦å‘Š
warnings.filterwarnings("ignore")

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="RAG ç©©å®šç‰ˆ", layout="wide")
st.title("ğŸ“˜ RAG æ–‡ä»¶å•ç­”ç³»çµ± (2025 ç©©å®šä¿®å¾©ç‰ˆ)")

# --- å®‰å…¨è®€å– Token ---
# å„ªå…ˆå¾ Streamlit Secrets è®€å–ï¼Œå¦å‰‡å¾å´é‚Šæ¬„è¼¸å…¥
hf_token = st.secrets.get("HUGGINGFACEHUB_API_TOKEN") or st.sidebar.text_input("è«‹è¼¸å…¥ HuggingFace Token", type="password")

if not hf_token:
    st.info("ğŸ‘‹ è«‹åœ¨å´é‚Šæ¬„è¼¸å…¥æ‚¨çš„ HuggingFace API Token ä»¥é–‹å§‹ã€‚")
    st.stop()

# --- è³‡æºè¼‰å…¥ (å¿«å–) ---
@st.cache_resource
def load_llm_and_embeddings(token):
    # ä½¿ç”¨ all-MiniLM-L6-v2 ä½œç‚º Embedding
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    
    # æ”¹ç”¨ HuggingFaceHub é¿é–‹ StopIteration Bug
    llm = HuggingFaceHub(
        repo_id="google/gemma-1.1-2b-it",
        huggingfacehub_api_token=token,
        model_kwargs={"max_new_tokens": 512, "temperature": 0.1}
    )
    return embeddings, llm

# --- PDF è™•ç†åŠŸèƒ½ ---
def process_uploaded_file(file):
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(file.getvalue())
        tmp_path = tmp.name
    
    loader = PyPDFLoader(tmp_path)
    # åˆ‡åˆ†æ–‡æœ¬
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)
    docs = loader.load_and_split(text_splitter)
    
    # å»ºç«‹å‘é‡åº«
    embeddings, _ = load_llm_and_embeddings(hf_token)
    vector_db = Chroma.from_documents(docs, embeddings)
    
    os.remove(tmp_path) # æ¸…ç†æš«å­˜æª”
    return vector_db

# --- ä¸»ç¨‹å¼é‚è¼¯ ---
embeddings_model, llm_model = load_llm_and_embeddings(hf_token)

uploaded_file = st.file_uploader("é¸æ“‡ PDF æ–‡ä»¶", type="pdf")

if uploaded_file:
    if "db" not in st.session_state:
        with st.spinner("æ­£åœ¨å»ºç«‹æ–‡ä»¶ç´¢å¼•..."):
            st.session_state.db = process_uploaded_file(uploaded_file)
            st.success("âœ… æ–‡ä»¶ç´¢å¼•å»ºç«‹æˆåŠŸï¼")

    # è¨­å®šæª¢ç´¢å™¨
    retriever = st.session_state.db.as_retriever(search_kwargs={"k": 3})

    # è¨­å®š Prompt (LCEL èªæ³•)
    prompt = ChatPromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„åŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹æä¾›çš„ Context (å…§å®¹) å›ç­”å•é¡Œã€‚
    å¦‚æœ Context ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹èª å¯¦å›ç­”ã€Œæˆ‘ä¸çŸ¥é“ã€ï¼Œä¸è¦ç·¨é€ ã€‚
    è«‹ä¸€å¾‹ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€å›ç­”ã€‚

    Context:
    {context}

    å•é¡Œ:
    {question}

    å›ç­”:""")

    # å»ºç«‹ RAG éˆ (å®Œå…¨é¿é–‹ langchain.chains)
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm_model
        | StrOutputParser()
    )

    # UI å•ç­”å€
    st.divider()
    user_input = st.text_input("ğŸ’¬ è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š")

    if user_input:
        with st.spinner("æ­£åœ¨æª¢ç´¢ä¸¦ç”Ÿæˆç­”æ¡ˆ..."):
            try:
                response = rag_chain.invoke(user_input)
                st.markdown("### ğŸ¤– AI å›ç­”")
                st.write(response)
                
                with st.expander("æŸ¥çœ‹åƒè€ƒä¾†æºç‰‡æ®µ"):
                    source_docs = retriever.get_relevant_documents(user_input)
                    for i, doc in enumerate(source_docs):
                        st.info(f"ä¾†æº {i+1}:\n{doc.page_content}")
            except Exception as e:
                st.error(f"åŸ·è¡Œæ™‚å‡ºéŒ¯ï¼š{str(e)}")
else:
    st.warning("ğŸ‘ˆ è«‹å…ˆä¸Šå‚³ PDF æ–‡ä»¶ã€‚")
